{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a92748d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5dbbbc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'Data/Stock News Data.csv',parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c297871",
   "metadata": {},
   "source": [
    "## 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5abbd4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>Hughes' instant hit buoys Blues</td>\n",
       "      <td>Jack gets his skates on at ice-cold Alex</td>\n",
       "      <td>Chaos as Maracana builds up for United</td>\n",
       "      <td>Depleted Leicester prevail as Elliott spoils E...</td>\n",
       "      <td>Hungry Spurs sense rich pickings</td>\n",
       "      <td>Gunners so wide of an easy target</td>\n",
       "      <td>...</td>\n",
       "      <td>Flintoff injury piles on woe for England</td>\n",
       "      <td>Hunters threaten Jospin with new battle of the...</td>\n",
       "      <td>Kohl's successor drawn into scandal</td>\n",
       "      <td>The difference between men and women</td>\n",
       "      <td>Sara Denver, nurse turned solicitor</td>\n",
       "      <td>Diana's landmine crusade put Tories in a panic</td>\n",
       "      <td>Yeltsin's resignation caught opposition flat-f...</td>\n",
       "      <td>Russian roulette</td>\n",
       "      <td>Sold out</td>\n",
       "      <td>Recovering a title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>The best lake scene</td>\n",
       "      <td>Leader: German sleaze inquiry</td>\n",
       "      <td>Cheerio, boyo</td>\n",
       "      <td>The main recommendations</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>...</td>\n",
       "      <td>On the critical list</td>\n",
       "      <td>The timing of their lives</td>\n",
       "      <td>Dear doctor</td>\n",
       "      <td>Irish court halts IRA man's extradition to Nor...</td>\n",
       "      <td>Burundi peace initiative fades after rebels re...</td>\n",
       "      <td>PE points the way forward to the ECB</td>\n",
       "      <td>Campaigners keep up pressure on Nazi war crime...</td>\n",
       "      <td>Jane Ratcliffe</td>\n",
       "      <td>Yet more things you wouldn't know without the ...</td>\n",
       "      <td>Millennium bug fails to bite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Label                                               Top1  \\\n",
       "0 2000-01-03      0  A 'hindrance to operations': extracts from the...   \n",
       "1 2000-01-04      0                                          Scorecard   \n",
       "\n",
       "                  Top2                             Top3  \\\n",
       "0            Scorecard  Hughes' instant hit buoys Blues   \n",
       "1  The best lake scene    Leader: German sleaze inquiry   \n",
       "\n",
       "                                       Top4  \\\n",
       "0  Jack gets his skates on at ice-cold Alex   \n",
       "1                             Cheerio, boyo   \n",
       "\n",
       "                                     Top5  \\\n",
       "0  Chaos as Maracana builds up for United   \n",
       "1                The main recommendations   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  Depleted Leicester prevail as Elliott spoils E...   \n",
       "1                             Has Cubie killed fees?   \n",
       "\n",
       "                               Top7                               Top8  ...  \\\n",
       "0  Hungry Spurs sense rich pickings  Gunners so wide of an easy target  ...   \n",
       "1            Has Cubie killed fees?             Has Cubie killed fees?  ...   \n",
       "\n",
       "                                      Top16  \\\n",
       "0  Flintoff injury piles on woe for England   \n",
       "1                      On the critical list   \n",
       "\n",
       "                                               Top17  \\\n",
       "0  Hunters threaten Jospin with new battle of the...   \n",
       "1                          The timing of their lives   \n",
       "\n",
       "                                 Top18  \\\n",
       "0  Kohl's successor drawn into scandal   \n",
       "1                          Dear doctor   \n",
       "\n",
       "                                               Top19  \\\n",
       "0               The difference between men and women   \n",
       "1  Irish court halts IRA man's extradition to Nor...   \n",
       "\n",
       "                                               Top20  \\\n",
       "0                Sara Denver, nurse turned solicitor   \n",
       "1  Burundi peace initiative fades after rebels re...   \n",
       "\n",
       "                                            Top21  \\\n",
       "0  Diana's landmine crusade put Tories in a panic   \n",
       "1            PE points the way forward to the ECB   \n",
       "\n",
       "                                               Top22             Top23  \\\n",
       "0  Yeltsin's resignation caught opposition flat-f...  Russian roulette   \n",
       "1  Campaigners keep up pressure on Nazi war crime...    Jane Ratcliffe   \n",
       "\n",
       "                                               Top24  \\\n",
       "0                                           Sold out   \n",
       "1  Yet more things you wouldn't know without the ...   \n",
       "\n",
       "                          Top25  \n",
       "0            Recovering a title  \n",
       "1  Millennium bug fails to bite  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6a3e5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4101, 27)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f79c76fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4101 entries, 0 to 4100\n",
      "Data columns (total 27 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Date    4101 non-null   datetime64[ns]\n",
      " 1   Label   4101 non-null   int64         \n",
      " 2   Top1    4101 non-null   object        \n",
      " 3   Top2    4101 non-null   object        \n",
      " 4   Top3    4101 non-null   object        \n",
      " 5   Top4    4101 non-null   object        \n",
      " 6   Top5    4101 non-null   object        \n",
      " 7   Top6    4101 non-null   object        \n",
      " 8   Top7    4101 non-null   object        \n",
      " 9   Top8    4101 non-null   object        \n",
      " 10  Top9    4101 non-null   object        \n",
      " 11  Top10   4101 non-null   object        \n",
      " 12  Top11   4101 non-null   object        \n",
      " 13  Top12   4101 non-null   object        \n",
      " 14  Top13   4101 non-null   object        \n",
      " 15  Top14   4101 non-null   object        \n",
      " 16  Top15   4101 non-null   object        \n",
      " 17  Top16   4101 non-null   object        \n",
      " 18  Top17   4101 non-null   object        \n",
      " 19  Top18   4101 non-null   object        \n",
      " 20  Top19   4101 non-null   object        \n",
      " 21  Top20   4101 non-null   object        \n",
      " 22  Top21   4101 non-null   object        \n",
      " 23  Top22   4101 non-null   object        \n",
      " 24  Top23   4100 non-null   object        \n",
      " 25  Top24   4098 non-null   object        \n",
      " 26  Top25   4098 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(25)\n",
      "memory usage: 865.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b6dc14",
   "metadata": {},
   "source": [
    "We have a date column, a label column, and 25 top news columns. Each row represents a day.\n",
    "\n",
    "We can see that some news headlines is missing for 'Top 24' and 'Top 25' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c473f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2166\n",
       "0    1935\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Check whether the class is balanced or not\n",
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df7cec",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc82bc",
   "metadata": {},
   "source": [
    "My Goal is to see if the news can affect the stock price on the same day, so the data column is not needed for this purpose. We also need to combine all 25 headlines into one document for later modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f3b690c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Headlines']=np.nan\n",
    "for i in range(len(df)):\n",
    "    df['Headlines'][i]=' '.join(str(x) for x in df.iloc[i,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69b136f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "      <th>Headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>Hughes' instant hit buoys Blues</td>\n",
       "      <td>Jack gets his skates on at ice-cold Alex</td>\n",
       "      <td>Chaos as Maracana builds up for United</td>\n",
       "      <td>Depleted Leicester prevail as Elliott spoils E...</td>\n",
       "      <td>Hungry Spurs sense rich pickings</td>\n",
       "      <td>Gunners so wide of an easy target</td>\n",
       "      <td>...</td>\n",
       "      <td>Hunters threaten Jospin with new battle of the...</td>\n",
       "      <td>Kohl's successor drawn into scandal</td>\n",
       "      <td>The difference between men and women</td>\n",
       "      <td>Sara Denver, nurse turned solicitor</td>\n",
       "      <td>Diana's landmine crusade put Tories in a panic</td>\n",
       "      <td>Yeltsin's resignation caught opposition flat-f...</td>\n",
       "      <td>Russian roulette</td>\n",
       "      <td>Sold out</td>\n",
       "      <td>Recovering a title</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>The best lake scene</td>\n",
       "      <td>Leader: German sleaze inquiry</td>\n",
       "      <td>Cheerio, boyo</td>\n",
       "      <td>The main recommendations</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>...</td>\n",
       "      <td>The timing of their lives</td>\n",
       "      <td>Dear doctor</td>\n",
       "      <td>Irish court halts IRA man's extradition to Nor...</td>\n",
       "      <td>Burundi peace initiative fades after rebels re...</td>\n",
       "      <td>PE points the way forward to the ECB</td>\n",
       "      <td>Campaigners keep up pressure on Nazi war crime...</td>\n",
       "      <td>Jane Ratcliffe</td>\n",
       "      <td>Yet more things you wouldn't know without the ...</td>\n",
       "      <td>Millennium bug fails to bite</td>\n",
       "      <td>Scorecard The best lake scene Leader: German s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Label                                               Top1  \\\n",
       "0 2000-01-03      0  A 'hindrance to operations': extracts from the...   \n",
       "1 2000-01-04      0                                          Scorecard   \n",
       "\n",
       "                  Top2                             Top3  \\\n",
       "0            Scorecard  Hughes' instant hit buoys Blues   \n",
       "1  The best lake scene    Leader: German sleaze inquiry   \n",
       "\n",
       "                                       Top4  \\\n",
       "0  Jack gets his skates on at ice-cold Alex   \n",
       "1                             Cheerio, boyo   \n",
       "\n",
       "                                     Top5  \\\n",
       "0  Chaos as Maracana builds up for United   \n",
       "1                The main recommendations   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  Depleted Leicester prevail as Elliott spoils E...   \n",
       "1                             Has Cubie killed fees?   \n",
       "\n",
       "                               Top7                               Top8  ...  \\\n",
       "0  Hungry Spurs sense rich pickings  Gunners so wide of an easy target  ...   \n",
       "1            Has Cubie killed fees?             Has Cubie killed fees?  ...   \n",
       "\n",
       "                                               Top17  \\\n",
       "0  Hunters threaten Jospin with new battle of the...   \n",
       "1                          The timing of their lives   \n",
       "\n",
       "                                 Top18  \\\n",
       "0  Kohl's successor drawn into scandal   \n",
       "1                          Dear doctor   \n",
       "\n",
       "                                               Top19  \\\n",
       "0               The difference between men and women   \n",
       "1  Irish court halts IRA man's extradition to Nor...   \n",
       "\n",
       "                                               Top20  \\\n",
       "0                Sara Denver, nurse turned solicitor   \n",
       "1  Burundi peace initiative fades after rebels re...   \n",
       "\n",
       "                                            Top21  \\\n",
       "0  Diana's landmine crusade put Tories in a panic   \n",
       "1            PE points the way forward to the ECB   \n",
       "\n",
       "                                               Top22             Top23  \\\n",
       "0  Yeltsin's resignation caught opposition flat-f...  Russian roulette   \n",
       "1  Campaigners keep up pressure on Nazi war crime...    Jane Ratcliffe   \n",
       "\n",
       "                                               Top24  \\\n",
       "0                                           Sold out   \n",
       "1  Yet more things you wouldn't know without the ...   \n",
       "\n",
       "                          Top25  \\\n",
       "0            Recovering a title   \n",
       "1  Millennium bug fails to bite   \n",
       "\n",
       "                                           Headlines  \n",
       "0  A 'hindrance to operations': extracts from the...  \n",
       "1  Scorecard The best lake scene Leader: German s...  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afde7f93",
   "metadata": {},
   "source": [
    "We can now drop off the individual news column now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "093a3306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>Scorecard The best lake scene Leader: German s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Label                                          Headlines\n",
       "0 2000-01-03      0  A 'hindrance to operations': extracts from the...\n",
       "1 2000-01-04      0  Scorecard The best lake scene Leader: German s..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['Date','Label','Headlines']]\n",
    "df.head()[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2924dfa",
   "metadata": {},
   "source": [
    "We can see many abbrevation used in the news. This can get avoided while cleaning. So, we need to replace the abbrevation with the actual meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "65d205b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8415a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_abbr(text):\n",
    "    abbr = []\n",
    "    for i in re.finditer(r\"([A-Za-z]+| )([A-Za-z]\\.){2,}\", text):\n",
    "        abbr.append(i.group())\n",
    "    df_abbr = pd.Series(abbr)\n",
    "    return df_abbr.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9cdbc7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_comb=' '.join(df.Headlines)\n",
    "abbr=find_abbr(news_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1b2c15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' A.I.', ' M.A.N.D.Y.', ' U.N.', ' U.S.', ' U.K.', ' S.A.',\n",
       "       ' U.S.C.', ' D.C.', ' N.J.', ' i.e.', ' P.I.', ' A.N.C.', ' a.m.',\n",
       "       ' A.K.A.', ' P.R.', ' R.I.', 'nU.S.', ' E.U.', ' H.I.V.',\n",
       "       ' I.H.T.', ' B.C.', ' J.P.', ' N.S.', 'crimese.g.', ' C.I.A.',\n",
       "       ' p.m.', 'Ph.D.', ' N.Y.', ' U.A.E.', 'sq.m.', ' I.M.F.', ' y.o.',\n",
       "       ' i.a.', ' I.D.', ' M.A.', ' H.W.', ' O.K.', ' N.K.', ' B.S.',\n",
       "       ' A.T.M.', ' W.H.O.', ' N.S.A.', ' P.M.', ' F.B.I.', ' P.E.I.',\n",
       "       ' a.k.a.', ' S.E.', ' A.D.', ' T.B.', ' J.K.', ' L.G.B.T.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abbr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab8610b",
   "metadata": {},
   "source": [
    "We need to replace all the abbrevation with actual meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fd22f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''convert abbrevations to full words'''\n",
    "for i in range(len(df)):\n",
    "    text = str(df.Headlines[i])\n",
    "    text = re.sub(r\"A.I.\", \" Area of Interest \", text)\n",
    "    text = re.sub(r\"M.A.N.D.Y.\", \" Drugs \", text)\n",
    "    text = re.sub(r\"A.T.M.\", \" Automated Teller Machine \", text)\n",
    "    text = re.sub(r\"C.I.A.\", \" Central Intelligence Agency \", text)\n",
    "    text = re.sub(r\"D.C.\", \" District of columbia \", text)\n",
    "    text = re.sub(r\"E.U.\", \" Europian Union \", text)\n",
    "    text = re.sub(r\"F.B.I.\", \" Federal Bureau of Investigation \", text)\n",
    "    text = re.sub(r\"H.I.V.\", \" Human immunodeficiency virus \", text)\n",
    "    text = re.sub(r\"I.H.T.\", \" inheritance tax \", text)\n",
    "    text = re.sub(r\"I.M.F.\", \" International Monetary Fund \", text)\n",
    "    text = re.sub(r\"I.D.\", \" identification \", text)\n",
    "    text = re.sub(r\"L.G.B.T.\", \" minority \", text)\n",
    "    text = re.sub(r\"M.A.\", \" Massachusetts \", text)\n",
    "    text = re.sub(r\"N.J.\", \" new jersey \", text)\n",
    "    text = re.sub(r\"N.K.\", \" north korea \", text)\n",
    "    text = re.sub(r\"N.S.A.\", \" National Security Agency \", text)\n",
    "    text = re.sub(r\"N.Y.\", \" new york \", text)\n",
    "    text = re.sub(r\"P.E.I.\", \" Prince Edward Island \", text)\n",
    "    text = re.sub(r\"P.M.\", \" prime minister \", text)\n",
    "    text = re.sub(r\"P.R.C\", \" china \", text)\n",
    "    text = re.sub(r\"S.A.\", \" south africa \", text)\n",
    "    text = re.sub(r\"R.I.\", \" Rhode Island \", text)\n",
    "    text = re.sub(r\"U.A.E.\", \" United Arab Emirates \", text)\n",
    "    text = re.sub(r\"U.K.\", \" england \", text)\n",
    "    text = re.sub(r\"U.N.\", \" New Jersey \", text)\n",
    "    text = re.sub(r\"U.S.\", \" America \", text)\n",
    "    text = re.sub(r\"U.S.C.\", \" University of south california \", text)\n",
    "    text = re.sub(r\"W.H.O\", \" world health organization \", text)\n",
    "    text = re.sub(r\"a.m.\", \" morning \", text)\n",
    "    text = re.sub(r\"p.m.\", \" afternoon \", text)\n",
    "    text = re.sub(r\"Ph.D.\", \" doctor of philosophy \", text)\n",
    "    text = re.sub(r\"sq.m.\", \" square meter \", text)\n",
    "    text = re.sub(r\"sq.m.\", \" square meter \", text)\n",
    "\n",
    "    df.Headlines[i]=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c57b9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_comb=' '.join(df.Headlines)\n",
    "abbr=find_abbr(news_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6ba2a602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' i.e.', ' P.I.', ' A.N.C.', ' A.K.A.', ' P.R.', ' B.C.', ' J.P.',\n",
       "       ' N.S.', 'crimese.g.', ' y.o.', ' i.a.', ' H.W.', ' O.K.', ' B.S.',\n",
       "       ' a.k.a.', ' S.E.', ' A.D.', ' T.B.', ' J.K.'], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' These are the abbrevations that are not important as they mostly \n",
    "contains the words from stop wrods'''\n",
    "abbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c08402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eecd98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "wl=WordNetLemmatizer()\n",
    "corpus=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48b874",
   "metadata": {},
   "source": [
    "### `For Bag of Words`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a65bc1",
   "metadata": {},
   "source": [
    "#### 1. Tokenize the text\n",
    "#### 2. Remove non-alphabetic characters and one-letter words, including numbers and punctuations\n",
    "#### 3. Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ba1fbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['headlines_str']=np.nan\n",
    "for i in range(len(df.Headlines)):\n",
    "    df.headlines_str[i]=df.Headlines[i].lower()\n",
    "    df.headlines_str[i]=re.sub(\"[^a-zA-z]\",\" \",df.headlines_str[i])\n",
    "    words=nltk.word_tokenize(df.headlines_str[i])\n",
    "    words=[wl.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    df.headlines_str[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383a9b9",
   "metadata": {},
   "source": [
    "### `For Word2vec --- Doc2vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c37aefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['headlines_words']=[df.headlines_str[i].split() for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e1d84836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>headlines_str</th>\n",
       "      <th>headlines_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "      <td>hindrance operation extract leaked report scor...</td>\n",
       "      <td>[hindrance, operation, extract, leaked, report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>Scorecard The best lake scene Leader: German s...</td>\n",
       "      <td>scorecard best lake scene leader german sleaze...</td>\n",
       "      <td>[scorecard, best, lake, scene, leader, german,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>Coventry caught on counter by Flo United's riv...</td>\n",
       "      <td>coventry caught counter flo united rival road ...</td>\n",
       "      <td>[coventry, caught, counter, flo, united, rival...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilgrim knows how to progress Thatcher facing ...</td>\n",
       "      <td>pilgrim know progress thatcher facing ban mcil...</td>\n",
       "      <td>[pilgrim, know, progress, thatcher, facing, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>Hitches and Horlocks Beckham off but United su...</td>\n",
       "      <td>hitch horlocks beckham united survive breast c...</td>\n",
       "      <td>[hitch, horlocks, beckham, united, survive, br...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Label                                          Headlines  \\\n",
       "0 2000-01-03      0  A 'hindrance to operations': extracts from the...   \n",
       "1 2000-01-04      0  Scorecard The best lake scene Leader: German s...   \n",
       "2 2000-01-05      0  Coventry caught on counter by Flo United's riv...   \n",
       "3 2000-01-06      1  Pilgrim knows how to progress Thatcher facing ...   \n",
       "4 2000-01-07      1  Hitches and Horlocks Beckham off but United su...   \n",
       "\n",
       "                                       headlines_str  \\\n",
       "0  hindrance operation extract leaked report scor...   \n",
       "1  scorecard best lake scene leader german sleaze...   \n",
       "2  coventry caught counter flo united rival road ...   \n",
       "3  pilgrim know progress thatcher facing ban mcil...   \n",
       "4  hitch horlocks beckham united survive breast c...   \n",
       "\n",
       "                                     headlines_words  \n",
       "0  [hindrance, operation, extract, leaked, report...  \n",
       "1  [scorecard, best, lake, scene, leader, german,...  \n",
       "2  [coventry, caught, counter, flo, united, rival...  \n",
       "3  [pilgrim, know, progress, thatcher, facing, ba...  \n",
       "4  [hitch, horlocks, beckham, united, survive, br...  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e67952d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d1c19f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word2vec model (trained on an enormous Google corpus)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(r'C:\\Users\\goura\\Documents\\DS and ML Projects\\8. Projects\\Stock Sentiment Analysis\\GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b59d476f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def doc2vec(model, wordlist):\n",
    "    '''\n",
    "    Use a word2vec embedding model to get the vecter of each word of the wordlist.\n",
    "    Now we have a list of vecters, len(list)= number of words in the doc, len(vector)= the model type, e.g.300\n",
    "    Convert each doc into a vector by np.mean. len(doc vec) = 300\n",
    "    '''\n",
    "    # Filter the list of vectors to include only those that Word2Vec has a vector for\n",
    "    vector_list = [model[word] for word in wordlist if word in model]\n",
    "    doc_vector = np.mean(vector_list, axis=0)\n",
    "    return doc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "4409f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each document (list of words) to a document vecter, then save into a list of doc_vec\n",
    "df['word2vec'] = [doc2vec(model, doc) for doc in df.headlines_words]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c90a74e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>headlines_str</th>\n",
       "      <th>headlines_words</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "      <td>hindrance operation extract leaked report scor...</td>\n",
       "      <td>[hindrance, operation, extract, leaked, report...</td>\n",
       "      <td>[0.019919062, 0.051673025, -0.025186863, 0.062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>Scorecard The best lake scene Leader: German s...</td>\n",
       "      <td>scorecard best lake scene leader german sleaze...</td>\n",
       "      <td>[scorecard, best, lake, scene, leader, german,...</td>\n",
       "      <td>[0.038909823, 0.049511578, 0.07234156, 0.05103...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>Coventry caught on counter by Flo United's riv...</td>\n",
       "      <td>coventry caught counter flo united rival road ...</td>\n",
       "      <td>[coventry, caught, counter, flo, united, rival...</td>\n",
       "      <td>[-0.028612338, 0.047972914, 0.013764942, 0.097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilgrim knows how to progress Thatcher facing ...</td>\n",
       "      <td>pilgrim know progress thatcher facing ban mcil...</td>\n",
       "      <td>[pilgrim, know, progress, thatcher, facing, ba...</td>\n",
       "      <td>[-0.021918356, 0.04694813, 0.03538333, 0.06647...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>Hitches and Horlocks Beckham off but United su...</td>\n",
       "      <td>hitch horlocks beckham united survive breast c...</td>\n",
       "      <td>[hitch, horlocks, beckham, united, survive, br...</td>\n",
       "      <td>[-0.014015404, 0.045476243, 0.021973068, 0.047...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Label                                          Headlines  \\\n",
       "0 2000-01-03      0  A 'hindrance to operations': extracts from the...   \n",
       "1 2000-01-04      0  Scorecard The best lake scene Leader: German s...   \n",
       "2 2000-01-05      0  Coventry caught on counter by Flo United's riv...   \n",
       "3 2000-01-06      1  Pilgrim knows how to progress Thatcher facing ...   \n",
       "4 2000-01-07      1  Hitches and Horlocks Beckham off but United su...   \n",
       "\n",
       "                                       headlines_str  \\\n",
       "0  hindrance operation extract leaked report scor...   \n",
       "1  scorecard best lake scene leader german sleaze...   \n",
       "2  coventry caught counter flo united rival road ...   \n",
       "3  pilgrim know progress thatcher facing ban mcil...   \n",
       "4  hitch horlocks beckham united survive breast c...   \n",
       "\n",
       "                                     headlines_words  \\\n",
       "0  [hindrance, operation, extract, leaked, report...   \n",
       "1  [scorecard, best, lake, scene, leader, german,...   \n",
       "2  [coventry, caught, counter, flo, united, rival...   \n",
       "3  [pilgrim, know, progress, thatcher, facing, ba...   \n",
       "4  [hitch, horlocks, beckham, united, survive, br...   \n",
       "\n",
       "                                            word2vec  \n",
       "0  [0.019919062, 0.051673025, -0.025186863, 0.062...  \n",
       "1  [0.038909823, 0.049511578, 0.07234156, 0.05103...  \n",
       "2  [-0.028612338, 0.047972914, 0.013764942, 0.097...  \n",
       "3  [-0.021918356, 0.04694813, 0.03538333, 0.06647...  \n",
       "4  [-0.014015404, 0.045476243, 0.021973068, 0.047...  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "b66c689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./preprocessed_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b972a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
